name: Prepare Small LLM
description: Download small LLM and launch it
runs:
  using: composite
  steps:
    - name: Download and unpack llama.cpp
      shell: bash
      run: |
        curl -OL https://github.com/ggerganov/llama.cpp/releases/download/b6887/llama-b6887-bin-ubuntu-x64.zip
        unzip llama-b6887-bin-ubuntu-x64.zip

    - name: Launch llama.cpp
      shell: bash
      run: ./build/bin/llama-server -c 4096 --hf-repo unsloth/granite-4.0-h-1b-GGUF --hf-file granite-4.0-h-1b-IQ4_XS.gguf &

    - name: Wait until it is ready
      shell: bash
      run: while ! curl -s 'http://localhost:8080/health' | grep 'ok'; do sleep 1; done
